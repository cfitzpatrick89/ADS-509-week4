{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Naive Bayes on Political Text\n",
    "\n",
    "### Conor Fitzpatrick\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cfitzpatrick/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"/Users/cfitzpatrick/Downloads/2020_Conventions (3).db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cfitzpatrick/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cfitzpatrick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_tokenize(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Path to the database\n",
    "db_path = \"/Users/cfitzpatrick/Downloads/nb-assignment-data/2020_Conventions.db\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "convention_db = sqlite3.connect(db_path)\n",
    "convention_cur = convention_db.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: [('conventions',)]\n"
     ]
    }
   ],
   "source": [
    "# Query to list all tables\n",
    "tables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "convention_cur.execute(tables_query)\n",
    "tables = convention_cur.fetchall()\n",
    "print(\"Tables in the database:\", tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of conventions table: [(0, 'party', 'TEXT', 0, None, 0), (1, 'night', 'INTEGER', 0, None, 0), (2, 'speaker', 'TEXT', 0, None, 0), (3, 'speaker_count', 'INTEGER', 0, None, 0), (4, 'time', 'TEXT', 0, None, 0), (5, 'text', 'TEXT', 0, None, 0), (6, 'text_len', 'TEXT', 0, None, 0), (7, 'file', 'TEXT', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    schema_query = f\"PRAGMA table_info({table_name});\"\n",
    "    convention_cur.execute(schema_query)\n",
    "    schema = convention_cur.fetchall()\n",
    "    print(f\"Schema of {table_name} table:\", schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cfitzpatrick/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/cfitzpatrick/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def clean_tokenize(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. As part of your cleaning process,\n",
    "# remove the stopwords from the text. The second element of the sublist\n",
    "# should be the party.\n",
    "\n",
    "query = '''\n",
    "SELECT text, party FROM conventions\n",
    "'''\n",
    "\n",
    "# Connect to the database\n",
    "convention_db = sqlite3.connect(\"/Users/cfitzpatrick/Downloads/2020_Conventions (3).db\")\n",
    "convention_cur = convention_db.cursor()\n",
    "\n",
    "query_results = convention_cur.execute(query)\n",
    "\n",
    "for row in query_results:\n",
    "    # Clean and tokenize the text\n",
    "    cleaned_text = clean_tokenize(row[0])\n",
    "    # Store the results in convention_data\n",
    "    convention_data.append([cleaned_text, row[1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_tokenize(text):\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     tokens = word_tokenize(text.lower())\n",
    "#     cleaned_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "#     return ' '.join(cleaned_tokens)\n",
    "\n",
    "\n",
    "# convention_data = []\n",
    "\n",
    "# # fill this list up with items that are themselves lists. The \n",
    "# # first element in the sublist should be the cleaned and tokenized\n",
    "# # text in a single string. As part of your cleaning process,\n",
    "# # remove the stopwords from the text. The second element of the sublist\n",
    "# # should be the party. \n",
    "\n",
    "# query = '''\n",
    "# SELECT text, party FROM speeches\n",
    "# '''\n",
    "\n",
    "# query_results = convention_cur.execute(query)\n",
    "\n",
    "# # for row in query_results :\n",
    "# #     # store the results in convention_data\n",
    "# #     pass # remove this\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['unified group around clean energy strategy', 'Democratic'],\n",
       " ['meg whitman longtime republican longtime ceo let tell donald trump clue run business let alone economy joe biden hand plan strengthen economy working people small business owners choice simple joe',\n",
       "  'Democratic'],\n",
       " ['every single family america affected cancer close', 'Democratic'],\n",
       " ['also moved joe work going back forth leader wrote violence women act enacted assault weapons ban vice president implemented recovery act brought country back great recessions championed affordable care act protecting millions americans preexisting conditions spent decades promoting american values interests around world',\n",
       "  'Democratic'],\n",
       " ['today beautiful daughter hope thriving old crystal fast approaching three years recovery dear friend constant inspiration others hold special place heart facing opioid addiction enormously grateful president leadership fighting deadly enemy efforts turning tide crisis addiction president trump declared opioid crisis public health emergency secured billion new federal funding help americans fight opioid abuse invested additional million stop opioid crisis rural america move strikes root problem implemented safer prescribing plan aimed reducing opioid prescriptions third within three years',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2236 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "        # Initialize an empty dictionary to store the features\n",
    "    ret_dict = dict()\n",
    "    \n",
    "    # Split the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Iterate over each word in the text\n",
    "    for word in words:\n",
    "        # If the word is in the feature words set, add it to the dictionary\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "    \n",
    "    return ret_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     27.1 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.8 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                  defund = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The accuracy on the test set is not very good at 49%. This is basically about what I would expect from randomly guessing. The most important features show some interesting insights. For Republicans, China is at the top of the list. This makes sense to me, since China is often seen as a big economical threat by many Republicans. The  top words for Republicans are not unexpected, like enforcement and destroy and freedoms. For Democrats, climate is the most common, which certainly makes sense, as the climate is a huge part of many Democrat platforms. Abraham being used by Democrats is interesting, maybe they want to identify with Lincoln? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/Users/cfitzpatrick/Downloads/nb-assignment-data (1)/congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pauldavisks calls amnesty illegal immigrants calls grant full citizenship remainred', 'Republican']\n",
      "['first time long time see budget language vote check rep homepage', 'Republican']\n",
      "['al green selected ranking member financial services subcommittee oversight investigations http', 'Democratic']\n",
      "['representative james clyburn joining today https', 'Democratic']\n",
      "['b photo thanks shipbuilders crew minnesota ssn hiindustries va hrva nn usnavy http', 'Democratic']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the tweet data for classification\n",
    "tweet_data = []\n",
    "\n",
    "for candidate, party, tweet_text in results:\n",
    "    cleaned_text = clean_tokenize(str(tweet_text))  # Ensure tweet_text is treated as a string\n",
    "    tweet_data.append([cleaned_text, party])\n",
    "\n",
    "# Close the database connection\n",
    "cong_db.close()\n",
    "\n",
    "# Check some random tweet entries\n",
    "random_tweets = random.sample(tweet_data, 5)\n",
    "for tweet in random_tweets:\n",
    "    print(tweet)\n",
    "\n",
    "# Feature sets for tweets\n",
    "tweet_featuresets = [(conv_features(text, feature_words), party) for (text, party) in tweet_data]\n",
    "\n",
    "# Take a random sample of tweets to see how our classifier does\n",
    "random.seed(20220507)\n",
    "random.shuffle(tweet_featuresets)\n",
    "\n",
    "test_size = 500\n",
    "test_set, train_set = tweet_featuresets[:test_size], tweet_featuresets[test_size:]\n",
    "tweet_classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(\"Classifier accuracy on tweet test set:\", nltk.classify.accuracy(tweet_classifier, test_set))\n",
    "\n",
    "# Show the most informative features\n",
    "tweet_classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: facebook stay date latest campaign https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: voted protect middle class economic recovery\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: offer thoughts prayers victims families students faculty taft hs entire taft community\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: fathers day guys work hard put families first dad https\n",
      "Actual party is Republican and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: drag friends vote willhaskellct bring remarkable new talent energy fight southwest connecticut future american politics indeed https\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample 5 random tweets from tweet_data for checking the classifier\n",
    "tweet_data_sample = random.sample(tweet_data, 5)\n",
    "\n",
    "for tweet, party in tweet_data_sample:\n",
    "    # Extract features from the tweet\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # Estimate the party using the classifier\n",
    "    estimated_party = tweet_classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for tweet, party in tweet_data_sample :\n",
    "#     estimated_party = 'Gotta fill this in'\n",
    "#     # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "#     print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "#     print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "#     print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Republican, Estimated: Republican, Count: 1114\n",
      "Actual: Republican, Estimated: Democratic, Count: 3262\n",
      "Actual: Democratic, Estimated: Republican, Count: 463\n",
      "Actual: Democratic, Estimated: Democratic, Count: 5163\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp    \n",
    "    # Extract features from the tweet\n",
    "    features = conv_features(tweet, feature_words)\n",
    "    \n",
    "    # Get the estimated party using the classifier\n",
    "    estimated_party = tweet_classifier.classify(features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score: \n",
    "        break\n",
    "\n",
    "# Let's print out the results\n",
    "for actual_party in parties:\n",
    "    for estimated_party in parties:\n",
    "        print(f\"Actual: {actual_party}, Estimated: {estimated_party}, Count: {results[actual_party][estimated_party]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[1114, 3262], [463, 5163]]\n",
      "Overall Accuracy: 0.6276\n",
      "Republican Precision: 0.7064\n",
      "Republican Recall: 0.2546\n",
      "Republican F1-score: 0.3743\n",
      "Democratic Precision: 0.6128\n",
      "Democratic Recall: 0.9177\n",
      "Democratic F1-score: 0.7349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Calculate the stats for easier analysis\n",
    "# Given counts\n",
    "true_positives_rep = 1114\n",
    "false_positives_rep = 463\n",
    "false_negatives_rep = 3262\n",
    "true_negatives_rep = 5163\n",
    "\n",
    "true_positives_dem = 5163\n",
    "false_positives_dem = 3262\n",
    "false_negatives_dem = 463\n",
    "true_negatives_dem = 1114\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = [\n",
    "    [true_positives_rep, false_negatives_rep],\n",
    "    [false_positives_rep, true_positives_dem]\n",
    "]\n",
    "\n",
    "# Actual and predicted labels based on the confusion matrix\n",
    "actual_labels = ['Republican'] * (true_positives_rep + false_negatives_rep) + ['Democratic'] * (false_positives_rep + true_positives_dem)\n",
    "predicted_labels = ['Republican'] * true_positives_rep + ['Democratic'] * false_negatives_rep + ['Republican'] * false_positives_rep + ['Democratic'] * true_positives_dem\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "precision_rep = precision_score(actual_labels, predicted_labels, pos_label='Republican')\n",
    "recall_rep = recall_score(actual_labels, predicted_labels, pos_label='Republican')\n",
    "f1_score_rep = f1_score(actual_labels, predicted_labels, pos_label='Republican')\n",
    "\n",
    "precision_dem = precision_score(actual_labels, predicted_labels, pos_label='Democratic')\n",
    "recall_dem = recall_score(actual_labels, predicted_labels, pos_label='Democratic')\n",
    "f1_score_dem = f1_score(actual_labels, predicted_labels, pos_label='Democratic')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Republican Precision: {precision_rep:.4f}\")\n",
    "print(f\"Republican Recall: {recall_rep:.4f}\")\n",
    "print(f\"Republican F1-score: {f1_score_rep:.4f}\")\n",
    "print(f\"Democratic Precision: {precision_dem:.4f}\")\n",
    "print(f\"Democratic Recall: {recall_dem:.4f}\")\n",
    "print(f\"Democratic F1-score: {f1_score_dem:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The Naive Bays accuracy overall was 62.7%, which is not particularly high. It seems that it is better able to predict Democrat tweets than Republicans, with an F1-score for dems at 73%, and only 37% for Republicans. F1-score is a balance of precision and recall, so it can be a good metric. What we see here is that the classifier really struggles to accurately identify republican tweets, and given the fact that it only has two options, these results are not particularly impressive. It is interesting to see the various words that were brough back in the feature importances. China being the most important for Republicans makes a lot of sense, and Democrats using words like Climate also makes a lot of sense. \n",
    "\n",
    "Going forward, we could try to do more digging in to the data to better understand what is going on, and see if we can find trends specifically within the Republican tweets that might help the overall accuracy. It is possible there are some differences in the collection of Republican or Democrat tweets, or some other factors we are not aware of. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
